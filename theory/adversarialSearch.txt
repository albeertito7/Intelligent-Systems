Adversarial Search
	
- decide how to act when there's an adversary/agent in your world
- you're not the only person action in the environment

We examine the problems that arise when we try to plan ahead in a world where other agents are planning against us

Multiagent environments:
	- each agent needs to consider the actions of other agents and how they affect its own welfare
	- the unpredictability of these other agents introduce contingencies, to act against the adversarials

GOAL:
	- to have a CONTINGENT PLAN to win the game, to neutralize the adversarial agents
	- we need to give a function which tells us in any given state what to do


We look into competitive environments, where agentsâ€™ goals are in conflict, giving rise to ADVERSARIAL GAMES


**Reflex agent: just look at ur possible actions and apply a functions about how good would be the actions but just think one step ahead, not building a tree as the minimax function**
**Reflex agent is not optimal and not exponential**


Most common games are: deterministic, turn-taking, two-player, zero-sum games of perfect information (e.g. chess)
    - Deterministic: you know the result of the actions
    - Turn-taking: game based on turns among players
    - Zero-sum: every gain of one player comes because the other is losing, balanced
    - Perfect information: we know every thing about the game, about the state of the game
    - Imperfect information: we don't know everything, a partial view (e.g. shooter: only is known our game view)
    - Chance: you don't know exactly the result of the actions, there is involved the probability


How to well describe a game formally? And then we will be able to apply algorithms

A deterministic game can be formally defined as a kind of search problem with the following elements:
    - S0: initial state: how the game is set up at the start
    - player(s): define which player has the move in a state s
    - actions(s): possible moves for a state, returns the set of legal moves in a state s
    - result(s, a): transition model, given a state and an action which is the result state
    - terminal-test(s): Is the game over? a test which is true when the game in a state is over or otherwise is false
    - utility(s, p):  
        - A utility function, defines the final numeric value for a game that ends in terminal state s for a player p
	- tells us for an end state s how much this is worth for a player p
        - In chess, outcome is a win, loss, or draw, with values +1, 0, or 1
        - defines the game result for the player p in a terminal state s
        - evaluation function; p = player
	- how good is the sate for the specified player


**The solution for a player is a policy which maps State to Actions**
**The initial state, ACTIONS function, and RESULT function define the game tree, where nodes are game states and the edges are moves**


Zero-Sum Games:
	- agents have opposite utilities
	- pure competition -> one function where one agent maximizes it the other agent minimizes it

General Games:
	- agent have independent utilities


Value Concept:
	- is the best achievable outcome (utility) from that state
	- for terminal states the value is known, given in the definition of the game
	- the max value of a state is defined to be the maximum of the value of its children

Minimax Value:
    - the best outcoume achievable under perfect play against an optimal adversary
    - needs to incorporate the idea of adversarial reasoning
    - is still known what's at the bottom/leafs of the tree because the game defines the terminal states
    - the adversary will try to minimize our utility function
    - the max player must maximize the adversarial possible values
    - computed recursively

Minimax Search:
    - a state-space search tree
    - turn-taking game
    - Compute each node's minimax value: the best achievable utility against a rational (optimal) adversary

Two Player Game (Max-Min) 
    - Max moves first
    - turn-taking untill the game is over
    - zero-sum game: the points go to winner and penalties to loser


Minimax Implementation:

    def max-value(state):
        if terminal state: return state's utility
        initialize v = -infinity
        for each sucessor of state:
            v = max(v, min-value(sucessor))
        return v
    
    def min-value(state):
        if terminal state: return state's utility
        initialize v= +infinity
        for each sucessor of state:
            v = min(v, max-value(sucessor))
        return v

    
MultiAgentMinimaxSearch:

    def value(state):
        if the next agent is MAX: return max-value(state)
        if the next agetn is MIN: return min-value(state)

    def max-value(state):
        if terminal state: return state's utility
        initialize v= -infinity
        for each successor of state:
            v = max(v, value(sucessor))
        return v
    
    def min-value(state):
        if terminal state: return state's utility
        initialize v= +infinity
        for each sucessor of state:
            v = min(v, value(sucessor))
        return v


Minimax Efficiency:
    - problem: the number of states to explore could be exponential, like DFS or BFS
    - where r is the branching factor and m is the depth level to be reached:
        - time: O(r^m) -> on each level the time will be more because of the exponential factor 
        - space: O(rm) -> the max possible space to have in our stack


OPTIMAL DECISION IN GAMES

- In a normal search problem, the optimal solution is a sequence of actions leading to a goal state (terminal state that is a win).
- In adversarial search, an optimal solution for MAX is a tree of actions specifying what to do depending of what MIN plays => CONTINGENT PLAN

Min player: the one its trying to take an action to minimize the utility function => the adversarial
Max player: via utility functions know how which possible moves will have to take the min player

Given a game tree, the optimal strategy can be determined from the MINIMAX VALUE of each node, which we write as MINIMAX(n).
**in a tree: nodes are states, edges are actions**

The minimax value of a node is the utility (for MAX) of being in the corresponding state

Obiously, the minimax value of a terminal state is just its utility

**Furthermore, if playing optimally, MAX preferes to move to a state of a maximum value whereas MIN prefers a state of minimum value**

**If MIN does not play optimally, MAX using the minimax algorithm will do even better**

Other strategies against suboptimal opponents may do better than the minimax strategy, but these strategies necessarily do worse against optimal opponents.

THE MINIMAX RECURSIVE ALGORITHM
    - use the second approach => recursive version
    - solved the problem about exponential memory required with the Bredth First Search Minimax algorithm