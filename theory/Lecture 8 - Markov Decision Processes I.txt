Markov Decision Processes
    - a way to formalize the idea of non-deterministic search

Non-Deterministic Search
    - when action outcomes are uncertain
    - the outcome isn't entirely under our control

Grid World
    - Maze-like problem
        - the agent lives in a grid
        - the walls block the agent's path
    - Noisy movement
        - actions do not always go as planned
    - the agent receives rewards each time step
        - small "living" reward each step (can be negative)
        - big rewards come at the end (good or bad)
    - two kind of rewards
        1. terminal utilities = big rewards
        2. each step
            - positive: walking is happier
            - negative: will cost pain at every step and things must end quickly
    - Goal:
        - Maximize the sum of rewards

Deterministic Grid World
    - action North -> outcome = North

Non-Deterministic/Stochastic Grid World
    - action North -> outcome?
        - 80% North
        - 10% West
        - 10% East
    - action affected by the ENVIRONMENT or other factors

**When planning we must take into account all the possible outcomes, and if they are worth it**


A MDP is defined by:
    - a set of states s ∈ S
    - a set of actions a ∈ A
    - a transition function T(s, a, s')
        - also called the model or the dynamics
    - a reward function R(s, a, s')
        - sometimes just R(s), or R(s')
    - a start state s
    - maybe a terminal state

MDP's are non-deterministic search problems
    - one way to solve them is with Expectimax Search